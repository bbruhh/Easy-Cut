{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLabCut Toolbox\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "\n",
    "A Mathis, alexander.mathis@bethgelab.org & M Mathis, mackenzie@post.harvard.edu\n",
    "\n",
    "This script generates the training data information for DeepCut (which requires a mat file)\n",
    "based on the pandas dataframes that hold label information. The user can set the fraction of \n",
    "the traing set size (from all labeled image in the hd5 file) and can create multiple shuffles. These parameters are set in myconfig.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from skimage import io\n",
    "import os, yaml, pickle,shutil,sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.getcwd().split('Generating_a_Training_Set')[0])\n",
    "from myconfig import Task, bodyparts, date, scorer, Shuffles, TrainingFraction\n",
    "import auxiliaryfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SplitTrials(trialindex, trainFraction=0.8):\n",
    "    ''' Split a trial index into train and test sets'''\n",
    "    trainsize = int(len(trialindex) * trainFraction)\n",
    "    shuffle = np.random.permutation(trialindex)\n",
    "    testIndexes = shuffle[trainsize:]\n",
    "    trainIndexes = shuffle[:trainsize]\n",
    "\n",
    "    return (trainIndexes, testIndexes)\n",
    "\n",
    "def boxitintoacell(joints):\n",
    "        ''' Auxiliary function for creating matfile.'''\n",
    "        outer = np.array([[None]], dtype=object)\n",
    "        outer[0,0]=np.array(joints,dtype='int64')\n",
    "        return outer\n",
    "\n",
    "def MakeTrain_pose_yaml(itemstochange,saveasfile,filename='pose_cfg.yaml'):\n",
    "    raw = open(filename).read()\n",
    "    docs = []\n",
    "    for raw_doc in raw.split('\\n---'):\n",
    "        try:\n",
    "            docs.append(yaml.load(raw_doc))\n",
    "        except SyntaxError:\n",
    "            docs.append(raw_doc)\n",
    "\n",
    "    for key in itemstochange.keys():\n",
    "        docs[0][key]=itemstochange[key]\n",
    "        \n",
    "    with open(saveasfile, \"w\") as f:\n",
    "        yaml.dump(docs[0], f)\n",
    "    return docs[0]\n",
    "\n",
    "def MakeTest_pose_yaml(dictionary,keys2save,saveasfile):\n",
    "    dict_test={}\n",
    "    for key in keys2save:\n",
    "        dict_test[key]=dictionary[key]\n",
    "\n",
    "    dict_test['scoremap_dir']='test'    \n",
    "    with open(saveasfile, \"w\") as f:\n",
    "        yaml.dump(dict_test, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#Loading scorer's data:\n",
    "folder='data-'+Task+'/'\n",
    "Data=pd.read_hdf(folder+'CollectedData_'+scorer+'.h5', 'df_with_missing')[scorer]\n",
    "\n",
    "bf=\"UnaugmentedDataSet_\"+Task+date+\"/\" #Make that folder and put in the collecteddata (see below)\n",
    "basefolder=\"../../\"+bf  #This relative path is required due way DeeperCut is structured\n",
    "#auxiliaryfunctions.attempttomakefolder(bf)\n",
    "shutil.copytree(folder,bf+folder)      #copy images and folder structure in the folder containing training data comparison\n",
    "         # ^ if this was run already, you will get an error that the folder exists!\n",
    "\n",
    "for shuffle in Shuffles:\n",
    "    for trainFraction in TrainingFraction:   \n",
    "        trainIndexes, testIndexes=SplitTrials(range(len(Data.index)), trainFraction)\n",
    "        filename_matfile=Task+\"_\"+scorer+str(int(100*trainFraction))+\"shuffle\"+str(shuffle)\n",
    "        # Filename for pickle file:\n",
    "        fn=bf+\"Documentation_\"+folder[:-1]+\"_\"+str(int(trainFraction*100))+\"shuffle\"+str(shuffle)\n",
    "\n",
    "        ####################################################\n",
    "        ######## Generating data structure with labeled information & frame metadata (for DeeperCut)\n",
    "        ####################################################\n",
    "    \n",
    "        # Make matlab train file!\n",
    "        data=[]\n",
    "        for jj in trainIndexes:\n",
    "                H={}\n",
    "                # load image to get dimensions:\n",
    "                filename=Data.index[jj]\n",
    "                im=io.imread(folder+filename)   \n",
    "                H['image']=basefolder+folder+filename\n",
    "         \n",
    "                if np.ndim(im)>2:\n",
    "                        H['size']=np.array([np.shape(im)[2],np.shape(im)[0],np.shape(im)[1]])\n",
    "                else:\n",
    "                        #print \"Grayscale!\"\n",
    "                        H['size']=np.array([1,np.shape(im)[0],np.shape(im)[1]])\n",
    "                \n",
    "                indexjoints=0\n",
    "                joints=np.zeros((len(bodyparts),3))*np.nan\n",
    "                for bpindex,bodypart in enumerate(bodyparts):\n",
    "                    if Data[bodypart]['x'][jj]<np.shape(im)[1] and Data[bodypart]['y'][jj]<np.shape(im)[0]: #are labels in image?\n",
    "                            joints[indexjoints,0]=int(bpindex)    \n",
    "                            joints[indexjoints,1]=Data[bodypart]['x'][jj]\n",
    "                            joints[indexjoints,2]=Data[bodypart]['y'][jj]       \n",
    "                            indexjoints+=1\n",
    "        \n",
    "                joints=joints[np.where(np.prod(np.isfinite(joints),1))[0],:] #drop NaN, i.e. lines for missing body parts\n",
    "            \n",
    "                assert(np.prod(np.array(joints[:,2])<np.shape(im)[0]))      #y coordinate within!\n",
    "                assert(np.prod(np.array(joints[:,1])<np.shape(im)[1]))\t\t#x coordinate within!\n",
    "        \n",
    "                H['joints']=np.array(joints,dtype=int)\n",
    "                if np.size(joints)>0: #exclude images without labels\n",
    "                    data.append(H)\n",
    "    \n",
    "        with open(fn+'.pickle', 'wb') as f:\n",
    "            # Pickle the 'data' dictionary using the highest protocol available.\n",
    "            pickle.dump([data,trainIndexes, testIndexes,trainFraction], f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    ################################################################################\n",
    "    ######### Convert to idosyncratic training file for deeper cut (*.mat)\n",
    "    ################################################################################\n",
    "    \n",
    "        DTYPE=[('image', 'O'), ('size', 'O'), ('joints', 'O')]             \t    \n",
    "        MatlabData=np.array([(np.array([data[item]['image']],dtype='U'),np.array([data[item]['size']]),boxitintoacell(data[item]['joints'])) for item in range(len(data))],dtype=DTYPE)\n",
    "        sio.savemat(bf+filename_matfile+'.mat',{'dataset': MatlabData})\n",
    "        \n",
    "        \n",
    "        ################################################################################\n",
    "        ######### Creating file structure for training & \n",
    "        ######### Test files as well as pose_yaml files (containing training and testing information)\n",
    "        #################################################################################\n",
    "\n",
    "        experimentname=Task+date+'-trainset'+str(int(trainFraction*100))+'shuffle'+str(shuffle)\n",
    "    \n",
    "        auxiliaryfunctions.attempttomakefolder(experimentname)\n",
    "        auxiliaryfunctions.attempttomakefolder(experimentname + '/train')\n",
    "        auxiliaryfunctions.attempttomakefolder(experimentname + '/test')\n",
    "        \n",
    "        items2change={\"dataset\": basefolder+filename_matfile+'.mat',\"num_joints\":len(bodyparts),\"all_joints\":[[i] for i in range(len(bodyparts))],\"all_joints_names\":bodyparts}\n",
    "        \n",
    "        trainingdata=MakeTrain_pose_yaml(items2change,experimentname+'/train/'+'pose_cfg.yaml',filename='pose_cfg.yaml')\n",
    "        keys2save=[\"dataset\",\"num_joints\",\"all_joints\",\"all_joints_names\",\"net_type\",'init_weights','global_scale','location_refinement','locref_stdev']    \n",
    "        MakeTest_pose_yaml(trainingdata,keys2save,experimentname+'/test/'+'pose_cfg.yaml')\n",
    "\n",
    "print(\"done!\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [DLCdependencies]",
   "language": "python",
   "name": "Python [DLCdependencies]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
